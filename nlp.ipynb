{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5028687f",
      "metadata": {
        "id": "5028687f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82e8ac37",
      "metadata": {
        "id": "82e8ac37"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow.python.compiler.mlcompute import mlcompute\n",
        "# mlcompute.set_mlc_device(device_name='any')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4b89cc3f",
      "metadata": {
        "id": "4b89cc3f"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4a29ac2a",
      "metadata": {
        "id": "4a29ac2a"
      },
      "outputs": [],
      "source": [
        "text = open(path_to_file, 'r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f5ced5c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "f5ced5c5",
        "outputId": "75278ca9-31d7-4a37-9e55-e8b7c177207c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9d14c412",
      "metadata": {
        "id": "9d14c412"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "15012b06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15012b06",
        "outputId": "e745234d-14a7-4204-9b33-6fc9add4e6f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82cb91fc",
      "metadata": {
        "id": "82cb91fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "38503035",
      "metadata": {
        "id": "38503035"
      },
      "outputs": [],
      "source": [
        "# for pair in enumerate(vocab):\n",
        "#     print(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b02bd376",
      "metadata": {
        "id": "b02bd376"
      },
      "outputs": [],
      "source": [
        "char_to_ind = {char:ind for ind, char in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "37769935",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37769935",
        "outputId": "4895ed55-9360-4315-82a8-4e16ab57152c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char_to_ind['H']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bd674682",
      "metadata": {
        "id": "bd674682"
      },
      "outputs": [],
      "source": [
        "index_to_char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a5b40019",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "a5b40019",
        "outputId": "47b1cc5e-eb44-44fd-bafc-7f3f0c050612"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'H'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_to_char[33]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6fc178bf",
      "metadata": {
        "id": "6fc178bf"
      },
      "outputs": [],
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2fcd51a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fcd51a8",
        "outputId": "094b1981-cd39-4e53-90a2-0bcd73a8d6a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627d05ea",
      "metadata": {
        "id": "627d05ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "255026cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "255026cf",
        "outputId": "3dd94245-138c-408d-8109-cb8c6e48ec72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a444ec2b",
      "metadata": {
        "id": "a444ec2b"
      },
      "outputs": [],
      "source": [
        "line = \"From fairest creatures we desire increase,\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "12161026",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12161026",
        "outputId": "6cc404bb-9226-4741-980b-ca0bd2fe8830"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3ca1c59d",
      "metadata": {
        "id": "3ca1c59d"
      },
      "outputs": [],
      "source": [
        "lines = '''\n",
        "From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9caeb5f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9caeb5f7",
        "outputId": "44db793c-b30a-473c-8f60-edbdcac26e1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8a3a986f",
      "metadata": {
        "id": "8a3a986f"
      },
      "outputs": [],
      "source": [
        "seq_len = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d829bd8e",
      "metadata": {
        "id": "d829bd8e"
      },
      "outputs": [],
      "source": [
        "tota_num_seq = len(text) // (seq_len+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "89116241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89116241",
        "outputId": "1b636da6-e449-4e3c-c1b7-74b2703bde4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tota_num_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b1ac2058",
      "metadata": {
        "id": "b1ac2058"
      },
      "outputs": [],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "31db9f7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31db9f7a",
        "outputId": "4de1e155-eefb-4a43-96ef-103ac8360596"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(char_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3d6fcf7e",
      "metadata": {
        "id": "3d6fcf7e"
      },
      "outputs": [],
      "source": [
        "# for item in char_dataset.take(500):\n",
        "#     print(index_to_char[item.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e4be8b1e",
      "metadata": {
        "id": "e4be8b1e"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d0b30306",
      "metadata": {
        "id": "d0b30306"
      },
      "outputs": [],
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_text = seq[:-1]\n",
        "    target_text = seq[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b48b7a6e",
      "metadata": {
        "id": "b48b7a6e"
      },
      "outputs": [],
      "source": [
        "datasets = sequences.map(create_seq_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "83a5cc55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83a5cc55",
        "outputId": "7ffbf335-f62d-4868-a4c0-a90a58a2e58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_text, target_text in datasets.take(1):\n",
        "    print(input_text.numpy())\n",
        "    print(\"\".join(index_to_char[input_text.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_text.numpy())\n",
        "    print(\"\".join(index_to_char[target_text.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a24e4c98",
      "metadata": {
        "id": "a24e4c98"
      },
      "outputs": [],
      "source": [
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f8a1b940",
      "metadata": {
        "id": "f8a1b940"
      },
      "outputs": [],
      "source": [
        "buffer_size = 10000\n",
        "datasets = datasets.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c8cd0858",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cd0858",
        "outputId": "1a266535-5732-48e2-ea1e-7b358d09b04d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int32, name=None), TensorSpec(shape=(128, 120), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46270c84",
      "metadata": {
        "id": "46270c84"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2c539dbf",
      "metadata": {
        "id": "2c539dbf"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "071119e4",
      "metadata": {
        "id": "071119e4"
      },
      "outputs": [],
      "source": [
        "embed_dim = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e9e7752c",
      "metadata": {
        "id": "e9e7752c"
      },
      "outputs": [],
      "source": [
        "rnn_neurons = 1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b450e0bc",
      "metadata": {
        "id": "b450e0bc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "eca51e3c",
      "metadata": {
        "id": "eca51e3c"
      },
      "outputs": [],
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6bb4d5cc",
      "metadata": {
        "id": "6bb4d5cc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5f159efb",
      "metadata": {
        "id": "5f159efb"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons, return_sequences=True,stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a797115d",
      "metadata": {
        "id": "a797115d"
      },
      "outputs": [],
      "source": [
        "model = create_model(vocab_size=vocab_size, embed_dim=embed_dim, rnn_neurons=rnn_neurons, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0d1742bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d1742bd",
        "outputId": "f7f01afa-b6dc-4d48-ff60-6a7be642f1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a4aac8",
      "metadata": {
        "id": "e4a4aac8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "75efd799",
      "metadata": {
        "id": "75efd799"
      },
      "outputs": [],
      "source": [
        "for input_example_batch, target_example_batch in datasets.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "888b71b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "888b71b2",
        "outputId": "9b922301-0f4d-4150-cbcc-d749085275c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_batch_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a15ae80d",
      "metadata": {
        "id": "a15ae80d"
      },
      "outputs": [],
      "source": [
        "sample_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "57081ee2",
      "metadata": {
        "id": "57081ee2"
      },
      "outputs": [],
      "source": [
        "sample_indices = tf.squeeze(sample_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a64c1f37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a64c1f37",
        "outputId": "a822ca98-d8b3-4431-d3d9-6f64549a5bac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([11, 53, 50, 33, 61, 56, 25, 14, 27,  5, 41,  5, 46, 39, 69, 22, 52,\n",
              "       52, 74, 78, 51, 22, 33, 22, 43, 16, 13, 45, 17, 21, 31, 79, 29, 40,\n",
              "       18, 74, 30, 29, 34, 69, 72, 78, 45, 46,  6, 35, 69, 74, 70, 23, 61,\n",
              "       43, 50, 50, 82, 53, 48, 45, 45, 52, 77, 12, 13, 68, 69, 31, 39, 46,\n",
              "       40, 46, 45,  5, 48,  6, 64, 14, 51,  5, 62, 33, 31, 38, 66, 16, 32,\n",
              "       55, 13, 65, 79, 51, 28, 69, 77,  1, 78, 33, 71, 40, 25, 31, 72, 56,\n",
              "       80, 17, 50, 26,  7, 70, 30, 33,  7, 45, 12, 27, 21, 66, 31, 77,  2,\n",
              "        0], dtype=int64)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "040fe134",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040fe134",
        "outputId": "f06860a7-1bcd-470f-da76-c517a0aa9497"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['0', ']', 'Y', 'H', 'f', 'a', '?', '3', 'B', \"'\", 'P', \"'\", 'U',\n",
              "       'N', 'n', ';', '[', '[', 's', 'w', 'Z', ';', 'H', ';', 'R', '5',\n",
              "       '2', 'T', '6', ':', 'F', 'x', 'D', 'O', '7', 's', 'E', 'D', 'I',\n",
              "       'n', 'q', 'w', 'T', 'U', '(', 'J', 'n', 's', 'o', '<', 'f', 'R',\n",
              "       'Y', 'Y', '|', ']', 'W', 'T', 'T', '[', 'v', '1', '2', 'm', 'n',\n",
              "       'F', 'N', 'U', 'O', 'U', 'T', \"'\", 'W', '(', 'i', '3', 'Z', \"'\",\n",
              "       'g', 'H', 'F', 'M', 'k', '5', 'G', '`', '2', 'j', 'x', 'Z', 'C',\n",
              "       'n', 'v', ' ', 'w', 'H', 'p', 'O', '?', 'F', 'q', 'a', 'y', '6',\n",
              "       'Y', 'A', ')', 'o', 'E', 'H', ')', 'T', '1', 'B', ':', 'k', 'F',\n",
              "       'v', '!', '\\n'], dtype='<U1')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_to_char[sample_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "0ebf1ac0",
      "metadata": {
        "id": "0ebf1ac0"
      },
      "outputs": [],
      "source": [
        "epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b5b87c0c",
      "metadata": {
        "id": "b5b87c0c"
      },
      "outputs": [],
      "source": [
        "# temp = list(datasets.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c354f93",
      "metadata": {
        "id": "8c354f93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ea4516",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ea4516",
        "outputId": "30cc5a7c-75b7-47f9-a2db-b944cc3e7932"
      },
      "outputs": [],
      "source": [
        "model.fit(datasets, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "93e87f72",
      "metadata": {
        "id": "93e87f72"
      },
      "outputs": [],
      "source": [
        "# model.save(\"nlp.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c8538217",
      "metadata": {
        "id": "c8538217"
      },
      "outputs": [],
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "model.load_weights('nlp.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "pAebwt3bmhDT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAebwt3bmhDT",
        "outputId": "acc09354-6d84-4f7d-d85b-e4b00a9712a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "cUYbjxoZniPk",
      "metadata": {
        "id": "cUYbjxoZniPk"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_seed,gen_size=500, temp=1.0):\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(index_to_char[predicted_id])\n",
        "  return start_seed + \"\".join(text_generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "R9d-XUqlqqPj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9d-XUqlqqPj",
        "outputId": "2ab1d52c-29f9-4535-9c00-73ad53f9bfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JULIETCK. It's butied for, I kill'd.            Exit\n",
            "  PROSPERO. Ay, in the heavy of you,\n",
            "    Sir England, what have we.\n",
            "    The rather for his golden are as second manner so inlawartly, them to pluck one enoughs; I speak\n",
            "    me. Yonder the thoughts\n",
            "    Like to a milk and that adulter deep,\n",
            "    And say thou art an old luce, weav'h\n",
            "    In the remembrance of my daughter's death.\n",
            "    I speak my mistress.\n",
            "  ANTONIO. Why, villain, art thou domandon?\n",
            "  JULIA. A dispossible advice it stays ithere    Turn this Captain Bourn's mind.      Exeunt.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Scene III.\n",
            "A lintth of Archbishops\n",
            "\n",
            "    F Simplicidy were but hearing of his knees\n",
            "    Give thee him.'\n",
            "    He has backward and uncurrent days her]\n",
            "     That Lantter to have the third time but their\n",
            "    fortune.\n",
            "  PAINTER. Fe brat of me?\n",
            "  Bene. Why let it be?\n",
            "  MIRANDA. I will not lie when I have so beholding to\n",
            "    your city hast thou touch'd the realm.\n",
            "  Lear. Not I turn th' Least of our friends. Go to, Peter- I confess it well.\n",
            "  COSTARD. I would have \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, \"JULIET\", gen_size=1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smURW5sPq41S",
      "metadata": {
        "id": "smURW5sPq41S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "285ddf65587f3c042e287c3856e7d92f4bb8cbaf58923bfd87e25b328822367e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
